"use client";

import type React from "react";
import { useState, useRef, useEffect, useCallback } from "react";
import { Send, Mic } from "lucide-react";
import { Button } from "@/components/ui/button"; // Import Button
import type {
	ChatMessage,
	Lesson,
	LessonQuiz,
	LlmContext,
	ChatAction,
	ActionType,
	LessonDatabase,
	StudentProfile,
	ClarificationOption, // Import the type if needed, assuming it's in index.ts
} from "@/types";
import {
	getChatLessonDatabase,
	getInitialStudentProfile,
} from "@/lib/data-service";
import { logger } from "@/lib/logger";

/**
 * Props for the Chat component.
 */
interface ChatProps {
	/** Callback function to dispatch actions to the parent component (e.g., for UI updates). */
	onAction: (action: ChatAction) => void;
	/** A message object to be processed as if the user sent it (e.g., from button clicks). */
	simulatedMessage: { text: string; id: number } | null;
	/** Callback function invoked after a simulated message has been processed. */
	onSimulatedMessageProcessed: () => void;
	/** The ID of the lesson currently displayed in the main application view. */
	activeLessonId: string | null;
}

/**
 * Represents the structured response expected from the LLM API endpoint.
 */
interface LlmResponse {
	/** The textual response generated by the LLM. */
	responseText: string;
	/** The type of action the UI should take (e.g., 'displayLessonContent', 'showQuiz'). */
	actionType?: string | null;
	/** The ID of the relevant lesson for the action. */
	lessonId?: string | null;
	/** The ID of the relevant quiz for the action. */
	quizId?: string | null;
	/** Partial updates to the LLM context based on the interaction. */
	contextUpdates?: Partial<LlmContext> | null;
	/** Markdown content for dynamically generated lessons. */
	lessonMarkdownContent?: string | null;
	/** Flag indicating if the LLM identified the previous user message as inappropriate. */
	flagsPreviousMessageAsInappropriate?: boolean | null;
	/** Optional reasoning provided by the LLM for its response or action. */
	reasoning?: string;
	generatedQuizData?: LessonQuiz[] | null; // Added for quiz generation
}

/**
 * Represents the overall structure of the response from the `/api/chat` endpoint.
 */
interface LlmApiResponse {
	/** The structured response from the LLM. */
	llmResponse: LlmResponse;
	/** An error message if the API call failed. */
	error?: string;
}

/**
 * Renders the chat interface, handles user input, interacts with the LLM API,
 * manages chat state, and triggers actions in the parent component.
 *
 * @param props - The component props.
 * @param props.onAction - Callback function to dispatch actions.
 * @param props.simulatedMessage - A message to process automatically.
 * @param props.onSimulatedMessageProcessed - Callback after processing a simulated message.
 * @param props.activeLessonId - The ID of the currently active lesson in the main view.
 * @returns The Chat component JSX.
 */
export default function Chat({
	onAction,
	simulatedMessage,
	onSimulatedMessageProcessed,
	activeLessonId,
}: ChatProps) {
  const [messages, setMessages] = useState<ChatMessage[]>([
    { text: "Hello! I'm your AI tutor. I can help you learn about numbers, operations, and more. What would you like to learn today?", type: "ai" }, // Corrected initial message to match ChatMessage type
  ])
  const [inputValue, setInputValue] = useState("")
  const messagesEndRef = useRef<HTMLDivElement>(null)
  const [isProcessing, setIsProcessing] = useState(false);
  const [chatDb, setChatDb] = useState<LessonDatabase | null>(null);

  const [llmContext, setLlmContext] = useState<LlmContext>({
    studentProfile: null,
    currentLesson: null, currentQuiz: null, progressHistory: [], recentInteractions: [],
    // Use Sets for efficient lookups, convert to array for API
    conceptsIntroduced: new Set<string>(),
    conceptsMastered: new Set<string>(),
    conceptsStruggling: new Set<string>(),
  });

 /**
  * Fetches initial student profile and lesson database on component mount.
  */
 const fetchInitialData = useCallback(async () => {
  setIsProcessing(true);
  try {
  	const [profile, database] = await Promise.all([
  		getInitialStudentProfile(),
  		getChatLessonDatabase(),
  	]);
  	setLlmContext((prev) => ({
  		...prev,
  		studentProfile: profile,
  		recentInteractions: [], // Clear history on initial load
  	}));
  	setChatDb(database);
  } catch (error) {
  	logger.error("Error fetching initial chat data", {
  		...(error instanceof Error
  			? { message: error.message, stack: error.stack, name: error.name }
  			: { error }),
  		component: "Chat",
  	});
  	setMessages((prev) => [
  		...prev,
  		{ text: "Error loading chat data.", type: "ai" },
  	]);
  } finally {
  	setIsProcessing(false);
  }
 }, []); // Empty dependency array ensures this runs only once on mount

 // Effect to fetch initial data
 useEffect(() => {
  fetchInitialData();
 }, [fetchInitialData]);


 /**
  * Updates the LLM context to reflect the currently active lesson.
  * Also adds the lesson's concepts to the `conceptsIntroduced` set.
  *
  * @param lessonId - The ID of the lesson to set as current.
  */
 const setCurrentLesson = useCallback((lessonId: string) => {
  if (!chatDb) return;
  const lessonData = chatDb[lessonId];
    if (!lessonData) {
        logger.warn(`Lesson data not found in chatDb for ID: ${lessonId}`, { component: 'Chat', lessonId });
        return;
    }
    setLlmContext((prev: LlmContext) => {
        const newIntroduced = new Set(prev.conceptsIntroduced);
        lessonData.concepts?.forEach((concept: string) => newIntroduced.add(concept));
        return {
            ...prev,
            currentLesson: { id: lessonId, data: lessonData, startTime: new Date(), progressPercentage: 0 },
            currentQuiz: null, // Reset quiz when lesson changes
            conceptsIntroduced: newIntroduced
        };
    });
  }, [chatDb]);

 /**
  * Updates the LLM context to reflect the currently active quiz within a lesson.
  * Ensures the corresponding lesson context is also set.
  *
  * @param lessonId - The ID of the lesson containing the quiz.
  * @param quizId - The ID of the quiz to set as current.
  */
 const setCurrentQuiz = useCallback((lessonId: string, quizId: string) => {
  if (!chatDb) return;
  const lesson = chatDb[lessonId];
    const quizData = lesson?.quizzes?.find((q: LessonQuiz) => q.id === quizId);
    if (!lesson || !quizData) {
        logger.warn(`Quiz data not found in chatDb for lesson ${lessonId}, quiz ${quizId}`, { component: 'Chat', lessonId, quizId });
        return;
    }
    setLlmContext((prev: LlmContext) => ({
        ...prev,
        // Ensure currentLesson is set if navigating directly to a quiz (might need adjustment)
        currentLesson: prev.currentLesson?.id === lessonId ? prev.currentLesson : { id: lessonId, data: lesson, startTime: new Date(), progressPercentage: 0 },
        currentQuiz: { id: quizId, data: quizData, startTime: new Date(), attempts: 0, answers: {}, correctCount: 0 }
    }));
  }, [chatDb]);

  // Scroll effect
  useEffect(() => {
    scrollToBottom()
  }, [messages])

 /**
  * Scrolls the chat message container to the bottom smoothly.
  */
 const scrollToBottom = () => {
  messagesEndRef.current?.scrollIntoView({ behavior: "smooth" });
 };


	// --- Helper Functions for processSubmission ---

	/**
	 * Updates the chat messages state, adding user/AI messages and handling typing indicators.
	 * @param type - The type of update ('addUser', 'addAi', 'addTyping', 'removeTyping').
	 * @param text - The text content for 'addUser' or 'addAi'.
	 */
	const updateChatMessages = useCallback((type: 'addUser' | 'addAi' | 'addTyping' | 'removeTyping', text?: string, options?: ClarificationOption[]) => {
		setMessages(prev => {
			switch (type) {
				case 'addUser':
					// Use type: 'user' as defined in ChatMessage
					if (text) return [...prev, { text, type: 'user' }];
					break;
				case 'addAi':
					// Use type: 'ai' and include clarificationOptions if provided
					if (text) return [...prev, { text, type: 'ai', clarificationOptions: options }];
					break;
				case 'addTyping':
					// Avoid adding multiple typing indicators
					if (!prev.some(msg => msg.type === 'typing')) {
						// Use type: 'typing'
						return [...prev, { text: 'Assistant is typing...', type: 'typing' }];
					}
					break;
				case 'removeTyping':
					return prev.filter(msg => msg.type !== 'typing');
			}
			return prev; // Return previous state if no change
		});
	}, []);

	/**
	 * Flags the last user message in the state as inappropriate.
	 */
	const flagInappropriateMessage = useCallback(() => {
		setMessages(prevMessages => {
			let lastUserMessageIndex = -1;
			for (let i = prevMessages.length - 1; i >= 0; i--) {
				if (prevMessages[i].type === 'user') { // Check type instead of role
					lastUserMessageIndex = i;
					break;
				}
			}
			if (lastUserMessageIndex !== -1) {
				return prevMessages.map((msg, index) =>
					index === lastUserMessageIndex ? { ...msg, isInappropriate: true } : msg
				);
			}
			return prevMessages;
		});
	}, []);


	/**
	 * Updates the LLM context based on the `contextUpdates` received from the API.
	 * @param contextUpdates - The partial context updates from the API response.
	 */
	const updateLlmContextFromApi = useCallback((contextUpdates: Partial<LlmContext> | null) => {
		if (!contextUpdates) return;

		setLlmContext(prev => {
			const newContext = { ...prev };
			// Update concepts (handle potential array format from API)
			if (contextUpdates.conceptsMastered && Array.isArray(contextUpdates.conceptsMastered)) {
				const updatedMastered = new Set(prev.conceptsMastered);
				contextUpdates.conceptsMastered.forEach(concept => updatedMastered.add(concept));
				newContext.conceptsMastered = updatedMastered;
			}
			 if (contextUpdates.conceptsStruggling && Array.isArray(contextUpdates.conceptsStruggling)) {
				const updatedStruggling = new Set(prev.conceptsStruggling);
				contextUpdates.conceptsStruggling.forEach(concept => updatedStruggling.add(concept));
				newContext.conceptsStruggling = updatedStruggling;
			}
			 if (contextUpdates.conceptsIntroduced && Array.isArray(contextUpdates.conceptsIntroduced)) {
				const updatedIntroduced = new Set(prev.conceptsIntroduced);
				contextUpdates.conceptsIntroduced.forEach(concept => updatedIntroduced.add(concept));
				newContext.conceptsIntroduced = updatedIntroduced;
			}
			// Add more context update logic here if needed (e.g., studentProfile)
			// TODO: Add studentProfile update logic if required by API
			return newContext;
		});
	}, []);

	/**
	 * Calls the backend chat API with the current message and context.
	 * @param messageText - The user's message.
	 * @returns A promise resolving to the API response.
	 */
	const callChatApi = useCallback(async (messageText: string): Promise<LlmApiResponse> => {
		if (!chatDb) {
			throw new Error("Chat database not loaded.");
		}

		// Prepare availableLessons from chatDb
		const availableLessons = Object.entries(chatDb).reduce((acc, [id, lesson]) => {
			acc[id] = lesson.title;
			return acc;
		}, {} as Record<string, string>);

		// Get currentLessonData if a lesson is active
		const currentLessonData = llmContext.currentLesson?.id ? chatDb[llmContext.currentLesson.id] : null;

		// Determine the immediate next step
		let immediateNextStep: { type: string; id: string } | null = null;
		if (
			!llmContext.currentQuiz &&
			currentLessonData?.quizzes?.length
		) {
			immediateNextStep = { type: 'quiz', id: currentLessonData.quizzes[0].id };
			logger.debug("Setting immediateNextStep to first quiz", { component: 'Chat', lessonId: currentLessonData.id, quizId: immediateNextStep.id });
		}

		// Prepare serializable context for the API
		const serializableLlmContext = {
			studentProfile: llmContext.studentProfile,
			currentLesson: activeLessonId ? { id: activeLessonId } : null,
			currentQuiz: llmContext.currentQuiz ? { id: llmContext.currentQuiz.id } : null,
			conceptsIntroduced: Array.from(llmContext.conceptsIntroduced),
			conceptsMastered: Array.from(llmContext.conceptsMastered),
			conceptsStruggling: Array.from(llmContext.conceptsStruggling),
			progressHistory: llmContext.progressHistory,
			recentInteractions: llmContext.recentInteractions,
		};

		try {
			const res = await fetch('/api/chat', {
				method: 'POST',
				headers: { 'Content-Type': 'application/json' },
				body: JSON.stringify({
					currentUserMessage: messageText,
					currentLlmContext: serializableLlmContext,
					availableLessons: availableLessons,
					currentLessonData: currentLessonData,
					immediateNextStep: immediateNextStep,
				}),
			});

			const apiResponse: LlmApiResponse = await res.json();
			logger.debug("Full API Response", { apiResponse, status: res.status, component: 'Chat' });

			if (!res.ok || apiResponse.error) {
				logger.error(`API Error (${res.status})`, { error: apiResponse.error || res.statusText, status: res.status, component: 'Chat' });
				// Construct a standard error response structure
				return {
					llmResponse: { responseText: `Error: ${apiResponse.error || res.statusText || "Unknown API error"}` },
					error: apiResponse.error || res.statusText || "Unknown API error",
				};
			}
			return apiResponse; // Success
		} catch (error) {
			logger.error("Failed to fetch from chat API", { ...(error instanceof Error ? { message: error.message, stack: error.stack, name: error.name } : { error }), component: 'Chat' });
			// Construct a standard error response structure for network/fetch errors
			return {
				llmResponse: { responseText: "Failed to connect to the assistant. Please check your connection and try again." },
				error: "Network error or failed fetch.",
			};
		}
	}, [chatDb, llmContext, activeLessonId]); // Dependencies for API call


	/**
	 * Handles actions specified in the LLM API response (e.g., navigating lessons/quizzes).
	 * @param llmResponse - The LlmResponse object from the API.
	 */
	const handleApiResponseActions = useCallback((llmResponse: LlmResponse | null) => {
		if (!llmResponse?.actionType) return; // No action specified

		const { actionType, lessonId, quizId, lessonMarkdownContent, generatedQuizData } = llmResponse; // Added generatedQuizData
		logger.info(`Received action from API`, { component: 'Chat', actionType, lessonId, quizId, hasGeneratedQuiz: !!generatedQuizData }); // Log if quiz data is present

		// Handle local context changes based on action
		if (actionType === 'displayLessonContent' && lessonId) {
			logger.info(`Executing 'displayLessonContent' action`, { component: 'Chat', lessonId });
			setCurrentLesson(lessonId);
		} else if (actionType === 'showQuiz' && lessonId && quizId) {
			logger.info(`Executing 'showQuiz' action`, { component: 'Chat', lessonId, quizId });
			setCurrentQuiz(lessonId, quizId);
		} else if (actionType === 'completeLesson') {
			logger.info(`Executing 'completeLesson' action`, { component: 'Chat', currentLessonId: llmContext.currentLesson?.id });
			setLlmContext((prev: LlmContext) => ({ ...prev, currentLesson: null, currentQuiz: null }));
	} else if (actionType === 'generateQuiz') {
			  logger.info(`Executing 'generateQuiz' action`, { component: 'Chat', quizCount: generatedQuizData?.length ?? 0 });
			  // No local context change needed here, just pass data to parent
	} else {
			// Log other actions but don't necessarily change local context unless needed
			logger.info(`Executing other action type`, { component: 'Chat', actionType, lessonId, quizId });
			// TODO: Implement handlers for other actions like returnToLessonOverview, showPreviousQuiz, showNextQuiz if needed for local state
		}

		// Warn if required IDs are missing for specific actions
		if (actionType === 'displayLessonContent' && !lessonId) {
			logger.warn(`'displayLessonContent' action received without lessonId`, { component: 'Chat', actionType });
		} else if (actionType === 'showQuiz' && (!lessonId || !quizId)) {
			logger.warn(`'showQuiz' action received with missing lessonId or quizId`, { component: 'Chat', actionType, lessonId, quizId });
		}

		// Trigger external action handler for parent component UI updates
		const actionPayload: ChatAction = {
			actionType: actionType as ActionType,
			lessonId: lessonId,
			quizId: quizId,
			lessonMarkdownContent: lessonMarkdownContent,
			generatedQuizData: generatedQuizData, // Pass generated quiz data
		};
		logger.info(`Calling onAction prop for UI update`, { component: 'Chat', action: actionPayload });
		onAction(actionPayload);

	}, [setCurrentLesson, setCurrentQuiz, onAction, llmContext.currentLesson?.id]); // Dependencies for action handling

	// --- End Helper Functions ---

	/**
	 * Handles clicks on clarification buttons.
	 * Sends the selected clarification value as a new user message.
	 * @param value - The value associated with the clicked button.
	 */
	const handleClarificationClick = (value: string) => {
		logger.debug("Clarification button clicked", { value, component: 'Chat' });
		// Sending a new message will make the previous one no longer the last,
		// automatically hiding the buttons based on the rendering logic.
		processSubmission(value);
	};


 /**
  * Handles the core logic for processing a user message or simulated action.
  * Sends the message and context to the API, updates state based on the response,
  * and triggers necessary actions.
  *
  * @param messageText - The text of the user's message or simulated action.
  */
 const processSubmission = useCallback(
 	async (messageText: string) => {
 		if (!messageText || isProcessing || !chatDb) return;

 		setIsProcessing(true);
 		updateChatMessages("addUser", messageText);

 		// Add user message to interactions history *before* API call
 		setLlmContext((prev) => ({
 			...prev,
 			recentInteractions: [...prev.recentInteractions, { user: messageText }],
 		}));

 		updateChatMessages("addTyping");

 		let apiResponse: LlmApiResponse | null = null;
 		try {
 			apiResponse = await callChatApi(messageText);

 			// Update LLM context based on API response (if successful)
 			if (apiResponse && !apiResponse.error) {
 				updateLlmContextFromApi(apiResponse.llmResponse?.contextUpdates ?? null);
 			}
 		} catch (error) {
 			// Error is logged within callChatApi, but we need a fallback response
 			logger.error("Error during callChatApi or context update", {
 				...(error instanceof Error
 					? { message: error.message, stack: error.stack, name: error.name }
 					: { error }),
 				component: "Chat",
 			});
 			// Ensure apiResponse is structured for error handling below
 			apiResponse = {
 				llmResponse: {
 					responseText:
 						"An unexpected error occurred while processing your request.",
 				},
 				error: "Processing error",
 			};
 		} finally {
 			updateChatMessages("removeTyping");
 		}

 		// --- Process API Results ---
 		const llmResponse = apiResponse?.llmResponse;
 		const responseText =
 			llmResponse?.responseText ??
 			"Sorry, something went wrong. Please try again.";

 		// Handle inappropriate flag
 		if (llmResponse?.flagsPreviousMessageAsInappropriate) {
 			flagInappropriateMessage();
 		}

 		// Add AI response message using the corrected updateChatMessages
 		// Assuming apiResponse.llmResponse might contain clarificationOptions even if not in local type def
 		const clarificationOptions = (apiResponse?.llmResponse as any)?.clarificationOptions;
 		updateChatMessages("addAi", responseText, clarificationOptions);

 		// Add AI response to interactions history
 		if (llmResponse) {
 			setLlmContext((prev) => ({
 				...prev,
 				recentInteractions: [
 					...prev.recentInteractions,
 					{ ai_response: llmResponse }, // Store the full LLM response part
 				],
 			}));
 		}

 		// Handle Actions specified by the API
 		handleApiResponseActions(llmResponse);

 		// Always set processing to false at the very end
 		setIsProcessing(false);
 	},
 	[ // Dependencies for processSubmission
 		isProcessing,
 		chatDb,
 		llmContext,
 		updateChatMessages,
 		callChatApi,
 		updateLlmContextFromApi,
 		flagInappropriateMessage,
 		handleApiResponseActions,
 		callChatApi,
 		updateLlmContextFromApi,
 		flagInappropriateMessage,
 		handleApiResponseActions,
 		updateChatMessages, // Add updateChatMessages as dependency
 		// Note: activeLessonId is used within callChatApi, so it's implicitly included via that dependency
 	]
 );

 /**
  * Handles the submission of the chat input form.
  * Prevents default form submission, trims the input value,
  * and calls `processSubmission` if the message is not empty.
  *
  * @param e - The form event object.
  */
 const handleSubmit = (e: React.FormEvent) => {
  e.preventDefault();
    const messageText = inputValue.trim();
    if (messageText) {
        processSubmission(messageText); // Call the core logic
        setInputValue(""); // Clear input after submission attempt
    }
  };

 // Effect to handle processing of simulated messages triggered by parent actions
 useEffect(() => {
  // Process simulated messages (e.g., from button clicks like "Next Activity")
  if (simulatedMessage && !isProcessing) {
  	logger.info(`Processing simulated user message`, {
  		component: "Chat",
  		messageText: simulatedMessage.text,
  	});
  	processSubmission(simulatedMessage.text)
  		.then(() => {
  			onSimulatedMessageProcessed(); // Notify parent that processing is done
  		})
  		.catch((error) => {
  			logger.error("Error processing simulated message", {
  				...(error instanceof Error
  					? { message: error.message, stack: error.stack, name: error.name }
  					: { error }),
  				component: "Chat",
  			});
  			// TODO: Consider if a more user-friendly error message is needed here
  			setMessages((prev) => [
  				...prev,
  				{ text: "Error processing action.", type: "ai" },
  			]);
  			onSimulatedMessageProcessed(); // Still notify parent on error
  		});
  }
 }, [
  simulatedMessage,
  isProcessing,
  processSubmission,
  onSimulatedMessageProcessed,
 ]);

  // --- JSX Structure (remains largely the same) ---
  return (
    <div className="flex flex-col h-full border-l bg-white">
        {!chatDb && (
            <div className="flex items-center justify-center h-full">
                <p>Loading chat...</p>
            </div>
        )}
        {chatDb && (
            <>
                <div className="flex-grow overflow-y-auto p-4 flex flex-col justify-end gap-2 bg-light-gray">
                {messages.map((message, index) => (
                    <div
                        key={`${message.type}-${index}-${message.text.slice(0, 10)}`} // Slightly more robust key
                        className={`flex flex-col mb-3 ${ // Use flex-col for message + buttons
                            message.type === "user" ? "items-end" : "items-start" // Align container based on type
                        }`}
                    >
                        {/* Message Bubble */}
                        <div
                            className={`p-3 rounded-2xl max-w-[85%] shadow-sm ${
                                message.type === "user"
                                ? "bg-user-msg text-[#0c5460] self-end rounded-br-sm" // User style
                                : message.type === "typing"
                                    ? "bg-transparent text-gray-500 italic self-start border-none shadow-none" // Typing style
                                    : "bg-ai-msg text-dark-gray self-start rounded-bl-sm border border-medium-gray" // AI style
                            } ${message.isInappropriate ? 'border-2 border-red-500 opacity-70' : ''}`} // Flagged style (adjusted opacity)
                        >
                            {message.type === 'typing' ? (
                                <div className="flex space-x-1">
                                    <span className="w-2 h-2 bg-gray-500 rounded-full animate-bounce" style={{ animationDelay: '0ms' }}></span>
                                    <span className="w-2 h-2 bg-gray-500 rounded-full animate-bounce" style={{ animationDelay: '150ms' }}></span>
                                    <span className="w-2 h-2 bg-gray-500 rounded-full animate-bounce" style={{ animationDelay: '300ms' }}></span>
                                </div>
                            ) : (
                                message.text
                            )}
                        </div>

                        {/* Clarification Buttons - Only for the LAST AI message with options */}
                        {message.type === 'ai' && // Check type 'ai'
                            index === messages.length - 1 && // Only for the last message
                            message.clarificationOptions &&
                            message.clarificationOptions.length > 0 && (
                                <div className="flex flex-wrap gap-2 mt-2 self-start"> {/* Ensure buttons align left */}
                                    {message.clarificationOptions.map((option, optionIndex) => (
                                        <Button
                                            key={optionIndex} // Use index within options for key
                                            variant="outline"
                                            size="sm"
                                            onClick={() => handleClarificationClick(option.value)}
                                            disabled={isProcessing} // Disable buttons while processing
                                            className="text-xs h-auto py-1 px-2" // Smaller button style
                                        >
                                            {option.label}
                                        </Button>
                                    ))}
                                </div>
                            )}
                    </div>

                ))}
                <div ref={messagesEndRef} />
                </div>

                <form onSubmit={handleSubmit} className="flex p-3 border-t border-medium-gray bg-white gap-2">
                <input
                    type="text"
                    value={inputValue}
                    onChange={(e) => setInputValue(e.target.value)}
                    placeholder="Ask a question..."
                    disabled={isProcessing || !chatDb}
                    className="flex-grow p-2 border border-medium-gray rounded-full outline-none focus:border-primary text-sm disabled:bg-gray-100"
                />
                <Button // Use Button component for Send
                    type="submit"
                    variant="default" // Or appropriate variant based on design system
                    size="icon" // Use icon size
                    disabled={isProcessing || !chatDb || !inputValue.trim()} // Disable if input is empty
                    className="w-9 h-9 bg-primary text-white rounded-full flex items-center justify-center hover:bg-primary-dark transition-colors disabled:bg-gray-400 disabled:cursor-not-allowed"
                >
                    <Send size={16} />
                </Button>
                <Button // Use Button component for Mic (optional)
                    type="button"
                    variant="outline" // Or appropriate variant
                    size="icon"
                    disabled={isProcessing || !chatDb} // Keep Mic enabled even if input empty for potential future use
                    className="w-9 h-9 bg-primary text-white rounded-full flex items-center justify-center hover:bg-primary-dark transition-colors disabled:bg-gray-400"
                    title="Voice input (not implemented)" // Add title for clarity
                >
                    <Mic size={16} />
                </Button>
                </form>
            </>
        )}
    </div>
  )
}
